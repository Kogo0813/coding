{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 127.5 - 1\n",
    "x_test = x_test / 127.5 - 1\n",
    "\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "\n",
    "NOISE_DIM = 10\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential([\n",
    "    Dense(256, input_dim=NOISE_DIM),\n",
    "    LeakyReLU(0.2),\n",
    "    Dense(512),\n",
    "    LeakyReLU(0.2),\n",
    "    Dense(1024),\n",
    "    LeakyReLU(0.2),\n",
    "    Dense(28*28, activation='tanh'),\n",
    "])\n",
    "\n",
    "discriminator = Sequential([\n",
    "    Dense(1024, input_shape=(784,), kernel_initializer=RandomNormal(stddev=0.02)),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.3),\n",
    "    Dense(512),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.3),\n",
    "    Dense(256),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(NOISE_DIM,))  # 10차원\n",
    "x = generator(inputs=gan_input)\n",
    "output = discriminator(x)\n",
    "gan = Model(gan_input, output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size):\n",
    "    batches = []\n",
    "    for i in range(int(data.shape[0] // batch_size)):\n",
    "        batch = data[i * batch_size: (i + 1) * batch_size]\n",
    "        batches.append(batch)\n",
    "    return np.asarray(batches)\n",
    "\n",
    "\n",
    "def visualize_training(epoch, d_losses, g_losses):\n",
    "    # 오차에 대한 시각화\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.plot(g_losses, label='Generatror Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print('epoch: {}, Discriminator Loss: {}, Generator Loss: {}'.format(\n",
    "        epoch, np.asarray(d_losses).mean(), np.asarray(g_losses).mean()))\n",
    "\n",
    "    # 샘플 데이터 생성 후 시각화\n",
    "    noise = np.random.normal(0, 1, size=(24, NOISE_DIM))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(-1, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(4, 6, i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "# discriminator와 gan 모델의 loss 측정을 위한 list 입니다.\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # 각 배치별 학습\n",
    "    for real_images in get_batches(x_train, BATCH_SIZE):\n",
    "        # 랜덤 노이즈 생성\n",
    "        input_noise = np.random.uniform(-1, 1, size=[BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "        # 가짜 이미지 데이터 생성\n",
    "        generated_images = generator.predict(input_noise)\n",
    "\n",
    "        # Gan에 학습할 X 데이터 정의\n",
    "        x_dis = np.concatenate([real_images, generated_images])\n",
    "\n",
    "        # Gan에 학습할 Y 데이터 정의\n",
    "        y_dis = np.zeros(2 * BATCH_SIZE)\n",
    "        y_dis[:BATCH_SIZE] = 0.9\n",
    "\n",
    "        # Discriminator 훈련\n",
    "        discriminator.trainable = True\n",
    "        d_loss = discriminator.train_on_batch(x_dis, y_dis)\n",
    "\n",
    "        # Gan 훈련\n",
    "        noise = np.random.uniform(-1, 1, size=[BATCH_SIZE, NOISE_DIM])\n",
    "        y_gan = np.ones(BATCH_SIZE)\n",
    "\n",
    "        # Discriminator의 판별 학습을 방지합니다\n",
    "        discriminator.trainable = False\n",
    "        g_loss = gan.train_on_batch(noise, y_gan)\n",
    "\n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_loss)\n",
    "\n",
    "    if epoch == 1 or epoch % 5 == 0:\n",
    "        visualize_training(epoch, d_losses, g_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "896dec041192bff481558047fad7d0e197250d6ee1a43bc027cd6e5b5fb3edf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
